# Syllabus 

## Textbook  

[The Elements of Statistical Learning](https://hastie.su.domains/Papers/ESLII.pdf)

[An Introduction to Statistical Learning](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf) 

## Reference  

Hastie’s homepage: [https://hastie.su.domains/index.html](https://hastie.su.domains/index.html) 

Friedman’s homepage: [https://jerryfriedman.su.domains](https://jerryfriedman.su.domains/) 

Python code for ISL: [https://github.com/JWarmenhoven/ISLR-python](https://github.com/JWarmenhoven/ISLR-python) 

## Books 

Computer-Age Statistical Inference 

Pattern Recognition and Machine Learning (Bible) 

Probabilistic Machine Learning: [https://probml.github.io/pml-book/book1.html](https://probml.github.io/pml-book/book1.html) 

PML: Advanced Topics: [https://probml.github.io/pml-book/book2.html](https://probml.github.io/pml-book/book2.html) 

## Open Courses(with video): 

1. Stanford ISL(Hastie): [https://www.edx.org/course/statistical-learning](https://www.edx.org/course/statistical-learning) 

2. NTU Machine Learning Foundation and Technics(林轩田) [https://www.coursera.org/instructor/htlin](https://www.coursera.org/instructor/htlin)  

3. BIMSA: Sequential Model and Time series [https://www.bimsa.cn/newsinfo/749652.html](https://www.bimsa.cn/newsinfo/749652.html) 

4. BIMSA: Bayesian Machine Learning [https://www.bimsa.cn/newsinfo/752150.html](https://www.bimsa.cn/newsinfo/752150.html) 

5. Bilibili: 机器学习白板推导 [https://www.bilibili.com/video/BV1aE411o7qd](https://www.bilibili.com/video/BV1aE411o7qd) 

## 正式组 requirement 

Lecture: 120-180 mins (1. content 2. slides(72h before 8pm Sat)) 

Assignment: problems in textbooks, proof in textbook and some papers, and code implementation 

Tutorial: lecture (continued), assignments, interview questions 

## Schedule 

Week 1(10.29): Orientation 

### Basic Topics 

Week 2(11.5): Introduction1-Linear Algebra (Xiaonan Peng) 

Week 3(11.12): Introduction2-Optimization (Xiaonan Peng) 

Week 4(11.19): Lecture 1: Linear Regression (Xiaonan Peng) 

ISL: 3.1-3.5; ESL: 3.1-3.2 

Week 5(11.26): Lecture 2: Linear Classification (Zhongcan Wang) 

ISL: 4.1-4.5; ESL: 4.1-4.2, 4.3.1-4.3.2, 4.4 

Week 6(12.3): Lecture 1(continued): Regularization (Xiaonan Peng) 

ISL: 6.1-6.2; ESL: 3.3-3.4 

Week 7(12.10): Tutorial 1(Xiaonan Peng) 

Week 8(12.17): Tutorial 2(Zhongcan Wang) 

Week 9 & 10: Break 

Week 11(1.7): Lecture 3: Resampling, model selection: CV and Bootstrap (Hao Ying) 

ISL: 5.1-5.2; ESL: 7.1-7.12, 8.1-8.4 

Week 12(1.14): Lecture 4: Additive Model and Kernel Smoothing Method (Bowei Fan) .14

ISL: 7.1-7.7; ESL: 5.1-5.6, 6.1-6.9 

Week 13: Break

Week 14(1.28): Interview question of regression(Xiaonan Peng)

Week 15(2.4): Tutorial 3(Hao Ying) 

Week 16(2.18): Tutorial 4(Bowei Fan)

Week 17(2.25): Lecture 5: Tree and Random Forest (Zhuangzhuang Han) 

ISL: 8.1, 8.2.1-8.2.2; ESL: 9.1-9.7, 15.1-15.4  

Week 18(3.4): Lecture 6: Adaboost (Zhe Yang) 

ISL: 8.2.3-8.2.5; ESL:10.1-10.14, 16.1-16.3 

Week 19(3.11): Break

Week 20(3.18): Tutorial 5 (Zhuangzhuang Han & Hao Ying) 

Week 21(3.25): Lecture 7: Deep Learning (Jade Tan) 

Week 22(4.1):  Lecture 6(Continued): Gradient Boost (Yang Zhe)

Week 23(4.8): Lecture 8: SVM (Xiaonan Peng) 

Week 25(4.15): Tutorial 8(Xiaonan Peng) 

Week 26(4.22): Tutorial 7(Jade Tan) 

Week 27: Break

### Advanced Topics 

Week 28(5.6): Lecture 9: Prototype Analysis ,KNN, and Survival Analysis (Bowei Fan) 

ISL: 11.1-11.7 ESL: 13.1-13.5 

Week 29(5.13): Lecture 11: Sparse Modeling and Lasso (Zhiyuan Li) 

CASI: 16.1-16.8  

Week 30(5.20): Lecture 12: EM Algorithm (Bin Han)  

Week 31(5.27): Lecture 13: Graphical Models (Optional)

ESL: 17.1-17.4; PRML: 8.1-8.4 

Week 32(6.3): Lecture 14: Sequential Data: HMM (Junlin Liu) 

PRML: 13.1-13.3 

Week 33(6.10): Lecture 15: Generative Model: VAE, Flow, and GAN (Hao Ying) 

PMLAdva: Part IV 

Week 34(6.17): Lecture 16: Diffusion Model (Optional)(Very Hot Topic!!!)

